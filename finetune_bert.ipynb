{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cpReJJJnkLF"
      },
      "source": [
        "# Personal Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB5pPtLUULtO"
      },
      "source": [
        "### Fine-tune a BERT model by adapting LoRA method for NER task using bc5cdr dataset\n",
        "\n",
        "https://huggingface.co/datasets/tner/bc5cdr?viewer_api=true\n",
        "\n",
        "- Entity Types: Chemical, Disease, Treatment\n",
        "\n",
        "- \"O\": 0\n",
        "- \"B-Chemical\": 1\n",
        "- \"B-Disease\": 2\n",
        "- \"I-Chemical\": 3\n",
        "- \"I-Disease\": 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj56BMayKdwS"
      },
      "source": [
        "### Installing Necessary Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShfdRLC5XcVN"
      },
      "source": [
        "Downgrading \"datasets\" library was necessary to be able to load the data later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ST1WJnS6wLE",
        "outputId": "5d775958-7990-44cf-c740-8d802daafda3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstallation complete\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "# --quiet suppresses installation messages\n",
        "!pip install transformers peft accelerate torch evaluate seqeval --quiet\n",
        "!pip install datasets==3.6.0 --quiet\n",
        "\n",
        "print(\"Installation complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQGAhiKqKlR9"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OCALiIw9YxW",
        "outputId": "9bac7b06-a3f4-47c4-8caf-4120379eb5b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForTokenClassification,  # Pre-trained BERT for NER\n",
        "    AutoTokenizer,                     # Converts text to numbers\n",
        "    TrainingArguments,                 # Settings for training\n",
        "    Trainer,                          # Handles the training loop\n",
        "    DataCollatorForTokenClassification # Prepares batches of data\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType  # LoRA components\n",
        "from datasets import load_dataset  # Download datasets\n",
        "import evaluate                     # Calculate metrics\n",
        "import numpy as np                  # Math operations\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "78vEFVv8th9W"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V_NEndZKrWQ"
      },
      "source": [
        "### Check GPU Availabiltiy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWqOV3zx9w0I",
        "outputId": "5ad663e5-574f-4fc5-c22a-c8808008c4f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available (Colab usually has one)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQnmdVDCKyc7"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397,
          "referenced_widgets": [
            "34561d6e91e64863900b03a3ff161ca6",
            "ef378c2788684e30a1a605257a0e845d",
            "873a66a0c1c04cb3a5e56118735d0043",
            "a88e87e1c7b0435492691928b1118e29",
            "f73ff75853824613b550d53c42ba8b11",
            "3301f4f9323149139a43f328e32e7d12",
            "38363cdcd3754854a3d7fe041ba3d4dd",
            "d52adda1ba4344b4911a95e2f9e0fd52",
            "d89349ddabc44281a415b97724fb67be",
            "42eceef4666f451fa584b7a33327927a",
            "126d00a122594981b64ee3df002b22cf",
            "b1dd17f9247143198498b80f9edd610f",
            "c99e6c9c849a4b158f586449665f9ba9",
            "ec2178c81f744804bc597c8b9d1d5b89",
            "ae13bfacc83e41e4b1293e63652ec387",
            "225b208b242f49d3af601f91759c0b41",
            "24fac8d62fdb466b97c977eef41e0576",
            "166764f4c6c54d19852b268cbe7792c6",
            "1829576805414a3ab83e7091ca0fd9ba",
            "f3ce94806ec34753bedf91544ae3b680",
            "a32617122d98471f8eadfd0dc90e574a",
            "b81acc274c734464a81ac5c3478a6060",
            "1d44b3071ede400eab168290f4c9b52e",
            "a6792c0a5aa84d15987376483fd21827",
            "2d46e321db84424f91b849d6b37bbdd4",
            "e3edfba247d54ee5bb27e4595d3be75a",
            "ec75f82deb624d5b9a77dd62bdca2a24",
            "fd2c0fd25b0e45c99b45736ead051e3d",
            "7ff1a6c6a31d458f88c447c7cd6b0fff",
            "4de24794a325490189c3f57ed386c065",
            "4c838f1575d347449840f7d6b3f9a6e5",
            "1c9995dc3a554a3f87fd13240be8ab22",
            "03afbe7306864dc990f0e2315fce3d18",
            "e4182514d77d476e8008d4bca261cb50",
            "36c64b12531343aebff9f97505bbb5df",
            "6e7496f9322e49d296b009dfc1f2a5d0",
            "d0e070d7ba294974b89c636d73252098",
            "7c97768511df4bed93b02179866aabea",
            "bad5e2006fec4c91aaa6ea15e7fd6b44",
            "56ae8e54f20b467b9c01b4133af793c4",
            "9593927770bb4b33b5cb67267953828a",
            "1b505e70f2fb4465aa8e55021582833e",
            "eaf5185e8f374aaba15c36a83054e77f",
            "b0fdfc67b65446d6a2a73af6ce5a7904",
            "a4b821d3ec2440efa3d0b0f951597493",
            "2da152540e774018b56a8dbad2cb05ee",
            "594f1dc011d14b9683127c3a9b9f6199",
            "b0fbae9700494f4fa7c2f5c673eb2bce",
            "75ffdaa2dc5e46ee9d18d04c06242744",
            "298a97859f9b404da12937a3e9e09652",
            "203d5b1de50441148f5bf7d088afd9c2",
            "835027f5b59d4e238529ebd4e0e201c7",
            "357b045502f34b4faabf68787bb6f117",
            "9bf778e4050047c0aabe2f5e5c45ccf5",
            "e5dff08ffd15464db28a3aa772c88d47",
            "023796594637440ebb273ad0f4e66891",
            "02a6e20d9c7c4f828c404ac37e36eaf8",
            "0ea09be3a2b04934a7702fe1c2632965",
            "6a560d6d86f541cc9060c7c007d0a85f",
            "3ae06bc7c9f549a99fb0f58393f5c0a0",
            "bd3cfa30693848bebcdb528c6c20ea1f",
            "7b04390900a9439ca0806735d5d6a1c5",
            "9587231c181443dfb7322553af6ecd2a",
            "2eee8072fc4d475e81483d3a7cb634ca",
            "84492aa7af754f91a1d6c04d912778d4",
            "03239860af82433d96080751a8759460",
            "03699bbad60d47dbb0e4e0be510b1a68",
            "672ae54e9a2248f68d4ee0cfa3dbb53a",
            "38d15b9e776b4dd7851d6b60e69059f7",
            "404e34618cdb470bad9a695a9c044a6e",
            "73edd303d041413db8727432ef56d8a3",
            "d5670bf807aa4909860b9a9735a9ba5f",
            "95faec8d2c6b4314beb05fe4f8fca917",
            "5fb7c917a85b460dbf5e0424d3d7fe6b",
            "e49ed8f3645a46a8b14e7f9767959a39",
            "943714026ba64a469b1529528a69cb38",
            "c4ad5e0d91bb4f70876ab237535a9504",
            "1caf986483dc4ca28b7ace693a1fe8b0",
            "88c9ed015de14347a9b2627770265a4f",
            "18f57ae922364440b7b9a6683845377d",
            "26e867c9715140ef95d0d77167b9bee7",
            "720ea360a10f47899179fbaae886b5ab",
            "31e827ea392f4bde9ed5cc99d4aa6c89",
            "0adfac7c718e48e1b61ca8be51975b32",
            "142ffe56a1a1421e9489270e0ef42dd2",
            "e40cafc4bc9a4b7293657b8634796a33",
            "c6a28df0dd294814b3b29816a9e98dc6",
            "8bcba2f299184e86bd2e4e112d61f3db"
          ]
        },
        "id": "5RoJyBgdPR12",
        "outputId": "d1b21e3a-f361-4b9d-cf6a-cedc223563f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34561d6e91e64863900b03a3ff161ca6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1dd17f9247143198498b80f9edd610f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "bc5cdr.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d44b3071ede400eab168290f4c9b52e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/367k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4182514d77d476e8008d4bca261cb50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/364k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4b821d3ec2440efa3d0b0f951597493",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/386k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "023796594637440ebb273ad0f4e66891",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/5228 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03699bbad60d47dbb0e4e0be510b1a68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/5330 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1caf986483dc4ca28b7ace693a1fe8b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/5865 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data = load_dataset(\"tner/bc5cdr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U0KfBExTO7B",
        "outputId": "08005e7e-e288-4725-bc00-fa7eaf9a7f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['tokens', 'tags'],\n",
            "        num_rows: 5228\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['tokens', 'tags'],\n",
            "        num_rows: 5330\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['tokens', 'tags'],\n",
            "        num_rows: 5865\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-22LN8jQ_iG",
        "outputId": "9cfd444d-f2e1-4782-c120-6d1c5c3093d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Training data: 5228\n",
            "   Testing data: 5865\n",
            "   Validation data: 5330\n"
          ]
        }
      ],
      "source": [
        "train_data= data[\"train\"]\n",
        "test_data = data[\"test\"]\n",
        "validation_data = data[\"validation\"]\n",
        "\n",
        "print(f\"   Training data: {len(train_data)}\")\n",
        "print(f\"   Testing data: {len(test_data)}\")\n",
        "print(f\"   Validation data: {len(validation_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwxQKkjFa0ql"
      },
      "source": [
        "One Example of a sentence and its respective labels/NER tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDSVOnXJX9uj",
        "outputId": "b58b340c-a8bd-4566-b245-11357ed0a424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tokens': ['Naloxone', 'reverses', 'the', 'antihypertensive', 'effect', 'of', 'clonidine', '.'], 'tags': [1, 0, 0, 0, 0, 0, 1, 0]}\n",
            "{'tokens': ['Famotidine', '-', 'associated', 'delirium', '.'], 'tags': [1, 0, 0, 2, 0]}\n"
          ]
        }
      ],
      "source": [
        "print(data[\"train\"][0])\n",
        "print(data[\"test\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93WZnpRmK660"
      },
      "source": [
        "Labels/NER Tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZHp9PwNFJoZ"
      },
      "source": [
        "* Entity Types: Chemical, Disease, Treatment\n",
        "\n",
        "- \"O\": 0\n",
        "- \"B-Chemical\": 1\n",
        "- \"B-Disease\": 2\n",
        "- \"I-Chemical\": 3\n",
        "- \"I-Disease\": 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yYhkfUg_TcF",
        "outputId": "52dbe733-09ff-4e97-faf2-8dcfce8bd494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entity types: {'O': 0, 'B-Chemical': 1, 'B-Disease': 2, 'I-Chemical': 3, 'I-Disease': 4}\n"
          ]
        }
      ],
      "source": [
        "label_list = {\n",
        "    \"O\": 0,\n",
        "    \"B-Chemical\": 1,\n",
        "    \"B-Disease\": 2,\n",
        "    \"I-Chemical\": 3,\n",
        "    \"I-Disease\": 4,\n",
        "}\n",
        "\n",
        "print(\"Entity types:\", label_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ16kTGlR6yC",
        "outputId": "1d132d5d-152d-4cee-c2dd-1d53e6b6fd1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   0: O\n",
            "   1: B-Chemical\n",
            "   2: B-Disease\n",
            "   3: I-Chemical\n",
            "   4: I-Disease\n",
            "\n",
            " Total labels: 5\n",
            "\n",
            "{0: 'O', 1: 'B-Chemical', 2: 'B-Disease', 3: 'I-Chemical', 4: 'I-Disease'}\n",
            "{'O': 0, 'B-Chemical': 1, 'B-Disease': 2, 'I-Chemical': 3, 'I-Disease': 4}\n"
          ]
        }
      ],
      "source": [
        "for i, label in enumerate(label_list):\n",
        "    print(f\"   {i}: {label}\")\n",
        "\n",
        "# Create mappings between numbers and labels\n",
        "id_to_label = {i: label for i, label in enumerate(label_list)}\n",
        "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "num_labels = len(label_list)\n",
        "print(f\"\\n Total labels: {num_labels}\")\n",
        "print(f\"\\n{id_to_label}\")\n",
        "print(f\"{label_to_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpAAL_r6LBgs"
      },
      "source": [
        "### Load BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf8N4YZ4FxRu",
        "outputId": "fbbb3cc1-d375-4caa-e17c-bd6737bd7c45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: google-bert/bert-base-uncased\n"
          ]
        }
      ],
      "source": [
        "model_name = \"google-bert/bert-base-uncased\"\n",
        "\n",
        "print(f\"Loading model: {model_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "e41c8a23a0c94706a7bfaeaa56b3e621",
            "cea1e0af4e4a41daad9642dc47f55551",
            "747b046aad2449b69a913f4a0a7bc3d0",
            "7ffbb339f72148b38d07740356073e4a",
            "cbc886ef730e4dd89d667a552c805c8a",
            "01dbaa01ba8045c181ad431f607c4fa2",
            "c379d3d5315242d1ab4c876fb005342a",
            "da374cefed5044d0b49bd6bf8acdcfd2",
            "608cd1abad7c45688bb48070a4960ce8",
            "d17bdbc38e8b490681c8b0b106e90f75",
            "870cfd9d5dd340899733ab75c7dd7226",
            "50f7ac10537844a48ab7bea9baab5ff6",
            "34c3c01f2c144f2693de4402bff02662",
            "f8c18cf5a0754c08a2e62dc0547d58de",
            "248a11e6a9764a69a33c4866eb5b4a9f",
            "7625c4b0d3d645de939af1d47e90e638",
            "079992ca2207425cb9de0b06a23200ee",
            "fdc9a618b225421c96245f2e4452d2d5",
            "455a82fef77a4ae480b3476615bc564c",
            "169a3350fb684244a7cbb596b7f98572",
            "77e0bb9b52364f899fcb1811da03f669",
            "ce4db46961644ea69805dbbc59da0e38",
            "9d1b4829b2bd4b4794652ee57a22893f",
            "e1327ca99dff4ae8ae6f57c297e741e8",
            "36ba0bbbb3b9425c8b09b83bbb6dbdbb",
            "94e07015d5394ccb9cd75172afc85902",
            "dae72fb5b40148569a64a5025c6136b0",
            "c4acadb1d6b5479887184bf907806944",
            "51267f84a1ff4b75bfb5c688cd40ed11",
            "e1f0c7efdb2e40adbca59878ae1137bd",
            "07a09a56541d4a07a0041894df3d29ac",
            "8e13c81841784f18981c3ca8d6adb0c3",
            "3efb9b1d21c948fe986107642c05459b",
            "45a4b23f3f344dca8c958bf7174c2867",
            "2cb20f6562c14ba2b891a0a10b811f0d",
            "7bcd8046ef8543b6924d0c9ae497076f",
            "772f6beaec644d39b3324ffab49f07b4",
            "3108b6fdd63f4bd3b06fefcd73e4887a",
            "ae9f61a92e7144d4846a1c1638645597",
            "10cf8b53a49b4cfc9f2328c93c240a84",
            "decccffe1be6418cb68030bcebd437a4",
            "811d9a5e0a3d48f287afe77f91dc4e56",
            "b4d6db5a4f5c421f8c5d558489f7d8ac",
            "59a018ffd02a4041af2ebde353bd5631"
          ]
        },
        "id": "E4khf-X0Tbhb",
        "outputId": "5443c5c9-b7ff-46e4-8d1b-55fb74907a65"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e41c8a23a0c94706a7bfaeaa56b3e621",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50f7ac10537844a48ab7bea9baab5ff6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d1b4829b2bd4b4794652ee57a22893f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45a4b23f3f344dca8c958bf7174c2867",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load tokenizer (converts words to numbers)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "904e0552af3c4d678f6933db57832e41",
            "1ef7a6c53378468fa2012012ff447706",
            "ac06dfd0c7fc4e689ddd00f237c0f6b0",
            "fed16e47b52748479b3b6f3bf63520db",
            "da98bb1545c74d579249b6424e52b15e",
            "a98fee96efee44b7b09ea18cd77e3b89",
            "706a1c7b89464ec4b1ca96b1d661bd64",
            "4d15d7cf68ec403ba205d70a08639964",
            "73881a5ea3544a85b9b084cb22d1d5eb",
            "4677466aad014d5f90653eff6fc0de84",
            "7c42251222224ffd91a2d843ddf4b40f"
          ]
        },
        "id": "ZrWmklFvTf2v",
        "outputId": "981b0356-1672-4574-f084-df6bb1c58876"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "904e0552af3c4d678f6933db57832e41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained model\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels ,\n",
        "    id2label=id_to_label,\n",
        "    label2id=label_to_id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0stoQwIh3Vk"
      },
      "source": [
        "BERT Architecture (can see that BERT is only built from Encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsHu1hGmhxKl",
        "outputId": "769ea6ce-e8ef-4624-be9e-a77d8d3e16e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertForTokenClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otKuo9C8TlD1",
        "outputId": "a31a7c05-fd58-4357-bb00-771e4a980ca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 108,895,493\n"
          ]
        }
      ],
      "source": [
        "# Move model to GPU\n",
        "model = model.to(device)\n",
        "print(f\"Total parameters: {model.num_parameters():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P78TBBpGgko"
      },
      "source": [
        "## Apply LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MoZORcQFGeTF"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.TOKEN_CLS,\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"query\", \"value\"], # Apply LoRA to query and value matrices\n",
        "    bias=\"none\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pWkTSPlAkwnW"
      },
      "outputs": [],
      "source": [
        "# model.unload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TKj7cBqNTpmB"
      },
      "outputs": [],
      "source": [
        "# Apply LoRA to the model\n",
        "model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWWhQ1h2msog"
      },
      "source": [
        "LoRA Applied BERT Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PkEoq2QmnW9",
        "outputId": "a6b49e9c-ff98-401c-bd44-ad602f08ace4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PeftModelForTokenClassification(\n",
            "  (base_model): LoraModel(\n",
            "    (model): BertForTokenClassification(\n",
            "      (bert): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0-11): 12 x BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSdpaSelfAttention(\n",
            "                  (query): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.05, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.05, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (classifier): ModulesToSaveWrapper(\n",
            "        (original_module): Linear(in_features=768, out_features=5, bias=True)\n",
            "        (modules_to_save): ModuleDict(\n",
            "          (default): Linear(in_features=768, out_features=5, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IZkplUDTr7W",
        "outputId": "db6cbf9c-7998-4c5a-aa60-4e8844c67a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 298,757 || all params: 109,194,250 || trainable%: 0.2736\n"
          ]
        }
      ],
      "source": [
        "# Show how many parameters will be trained\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNh4HUN5HmGH"
      },
      "source": [
        "### Tokenize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hk691ElaHp0v"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "\n",
        "    # Tokenize the words\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['tokens'],           # Input words\n",
        "        truncation=True,              # Cut if too long\n",
        "        is_split_into_words=True,     # Already split into words\n",
        "        padding='max_length',         # Pad to same length\n",
        "        max_length=128                # Max 128 tokens\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['tags']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens (CLS, SEP, PAD) get -100 (ignore)\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # First subword gets the real label\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # Additional subwords get -100 (ignore)\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "97d83bad24bf4761ab5d4215173e20dc",
            "7aa7d0c8514c400085fdf0c911568a58",
            "81ec53f6c67446fc9c2e6db64df30b5c",
            "17a409582b7a49efb1ae82090bb956ab",
            "9d293e3c76ec45ce9f540feaac001464",
            "f6a04e8afd904583845ba62ffc35dad4",
            "82867fec541a42fc9c5c72fe2982ff90",
            "6fde218b354a4398a8655882d30aea6b",
            "0c34e3ccc3494035b61b772735b2dac4",
            "c6203916b3804db49bde0c2c9a9240da",
            "7c915b3ad4de43a7974cbf4325831d26",
            "191cbfb2c6aa4da8b16f3773d5599159",
            "64bc275517414f4b95acf027fb47e18b",
            "7502b66b093d4e6fb939bd54733d0333",
            "4e3bb0d8c25f4f5bbfb1192f7354dcbe",
            "4c709166b27740469e5f5bdf5af61b38",
            "b8343e58619d47a8878eb072a462c6fe",
            "23575ae1bdd94f2cb459dd1ce2655b9a",
            "a76df8591b8e4231a450cc0c19602eff",
            "0e1d1c9696114fe3a8dfbfcdff5de9c8",
            "499196205ce04d1a93f9b332b40b9083",
            "d61198613ad54415b9f2c986f1958bfa",
            "3f0ac9c2e6da4f4fb8b65995320d36c9",
            "1be134ec54644ce1980748afd6f2cd7f",
            "f37f0ab2da28432c9b0aadb0d25da68a",
            "a544fd55735e4c02bb10932da9dd8e8f",
            "e868a6a9e2894ad297265e65a8741d0b",
            "ba9c2fd5e8d44842b92a46d36653bd1a",
            "083aa76c935f429499de1fceb91f03fd",
            "6f13e1acfaee4c5db2a172c572f157c2",
            "ba76f0187fa7420e8e44b1d5055db7a4",
            "5e816df9528c44a98fc8d374c395ef72",
            "636fceb2fc2748a1b40b17f35a359ffa"
          ]
        },
        "id": "kBBvlz3kT1b7",
        "outputId": "26bfba65-6cbd-4085-8ee5-74ca6af5cfbf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97d83bad24bf4761ab5d4215173e20dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5228 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "191cbfb2c6aa4da8b16f3773d5599159",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5330 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f0ac9c2e6da4f4fb8b65995320d36c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5865 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenization complete\n"
          ]
        }
      ],
      "source": [
        "# Apply tokenization to all data\n",
        "tokenized_datasets = data.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=data['train'].column_names\n",
        ")\n",
        "print(\"Tokenization complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM6IXOuWUBwe",
        "outputId": "1d6bd833-a6d5-4853-9cf9-89ed965c5e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 5228\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 5330\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 5865\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_datasets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft5tVUjvNXa1"
      },
      "source": [
        "### Define Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e75b3c7e02e84f4c8b1eba08ada5c8c1",
            "4267834cd60f477b9441eda1948d1d3e",
            "b6fb1243303c43f88e034dff2682a0e1",
            "d42cf6320b124f1bb4ef8c3cb965ed44",
            "9aeee64f03034d3ab134ec6c8f00efb3",
            "789c8b02077749bf908c51d41a4e9c98",
            "88b55e447c3d43f187c2c411733e1abf",
            "330f91f0543f424893b8e480fbd8beeb",
            "05ce1ded355642d7bdf284a3c1e0adc9",
            "e8ef8bfe092646d0a4ded0ae2a28f7c3",
            "0de567cc27fb4c8b8ba94dde15039dc9"
          ]
        },
        "id": "91Gn543RNZjH",
        "outputId": "79f53fdf-ee98-491c-96b5-51e67a6e743e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e75b3c7e02e84f4c8b1eba08ada5c8c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics function ready!\n"
          ]
        }
      ],
      "source": [
        "# Load seqeval metric (standard for NER)\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=2)  # Get the highest probability class\n",
        "\n",
        "    # Remove ignored tokens (-100)\n",
        "    true_predictions = [\n",
        "        [id_to_label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id_to_label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    # Calculate metrics\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "\n",
        "print(\"Metrics function ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6_XBQFdf6gE"
      },
      "source": [
        "### Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3VRbyioAf-VG"
      },
      "outputs": [],
      "source": [
        "# Set up training parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./lora-ner-results\",        # Where to save model\n",
        "    learning_rate=3e-4,                      # How fast to learn (higher for LoRA)\n",
        "    per_device_train_batch_size=16,         # Process 16 examples at once\n",
        "    per_device_eval_batch_size=16,          # Evaluate 16 at once\n",
        "    num_train_epochs=3,                     # Train for 3 full passes\n",
        "    weight_decay=0.01,                      # Prevent overfitting\n",
        "    eval_strategy=\"epoch\",            # Evaluate after each epoch\n",
        "    save_strategy=\"epoch\",                  # Save after each epoch\n",
        "    load_best_model_at_end=True,           # Keep the best model\n",
        "    logging_steps=50,                       # Log every 50 steps\n",
        "    fp16=True,                              # Use mixed precision (faster on GPU)\n",
        "    report_to=\"none\"                        # Don't send to tracking services\n",
        ")\n",
        "\n",
        "# Data collator (prepares batches)\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drtrEeTygh_a"
      },
      "source": [
        "### Create Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_mHZYQ7geOI",
        "outputId": "406311d8-8fa5-427d-aeae-0276ec7ab6bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainer ready!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1700590856.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "# Trainer handles all the training logic\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Trainer ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGO4n3fqhNoP"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jOECeVn8vV6V",
        "outputId": "be412535-8d2d-4d61-81b5-d81a50d638e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='981' max='981' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [981/981 02:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.144400</td>\n",
              "      <td>0.114421</td>\n",
              "      <td>0.771285</td>\n",
              "      <td>0.785020</td>\n",
              "      <td>0.778092</td>\n",
              "      <td>0.959167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.117300</td>\n",
              "      <td>0.104192</td>\n",
              "      <td>0.779090</td>\n",
              "      <td>0.831800</td>\n",
              "      <td>0.804583</td>\n",
              "      <td>0.962163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.103300</td>\n",
              "      <td>0.100203</td>\n",
              "      <td>0.791478</td>\n",
              "      <td>0.834100</td>\n",
              "      <td>0.812230</td>\n",
              "      <td>0.963841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo945xASiZjR"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "lhCouFgBiazg",
        "outputId": "d3e91eaf-2916-4515-b348-48dd2279c15a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='334' max='334' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [334/334 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Results:\n",
            "   Precision: 79.15%\n",
            "   Recall: 83.41%\n",
            "   F1-Score: 81.22%\n",
            "   Accuracy: 96.38%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation set\n",
        "results = trainer.evaluate()\n",
        "\n",
        "print(\"\\n Results:\")\n",
        "print(f\"   Precision: {results['eval_precision']:.2%}\")\n",
        "print(f\"   Recall: {results['eval_recall']:.2%}\")\n",
        "print(f\"   F1-Score: {results['eval_f1']:.2%}\")\n",
        "print(f\"   Accuracy: {results['eval_accuracy']:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV9VNRW1irjF"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XFFPmBrjMPN"
      },
      "source": [
        "- Saves only the LoRA (weights) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUzEjOncjJMw",
        "outputId": "fc0b08f1-4645-46af-dce9-9c2cb2e76c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved!\n"
          ]
        }
      ],
      "source": [
        "# Save the LoRA adapter (tiny file!)\n",
        "model.save_pretrained(\"./lora-bert-ner\")\n",
        "tokenizer.save_pretrained(\"./lora-bert-ner\")\n",
        "\n",
        "print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-sx-fyCgyi6q",
        "outputId": "aa584cfb-17ab-4c74-b8ba-f5768f1bd09e"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e8dda217-03e6-4715-a41d-0e296570c683\", \"model.zip\", 1433704)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "shutil.make_archive('model', 'zip', './lora-bert-ner')\n",
        "files.download('model.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
